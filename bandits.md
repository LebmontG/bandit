# 赌博机问题

## 上下文无关赌博机

给定一个智能体有限个动作的集合，智能体在每个回合基于先前的观察选择一个动作，并获得相应的奖励，其数值取决于动作本身以及一定的噪声。智能体需要在长期的交互过程中获得更大的奖励。
相比于一般强化学习问题，智能体不再具有状态或者仅仅具有一个状态，奖励与动作相关而非状态。而场景设定依然是在线的。
在推荐算法中，可以将一个推送内容视为动作集合中的一个动作，而智能体是推荐系统。系统一次向用户推荐一系列内容，用户选择其中的一部分后，系统得到相应的、先前设置的奖励的的过程，即智能体在一回合中选择一系列动作并获得奖励的过程。

## 上下文赌博机

相比于上下文无关赌博机，上下文赌博机考虑一系列的场景，奖励不再取决于动作本身，而是基于场景和动作的联合特征。
同样在推荐算法中，对于每一个用户建立一个相应的场景，对其推荐内容就会同时考虑其特征和内容特征，这会带来更加个性化的推荐。

## 决斗赌博机

传统的赌博机往往假设奖励仅与动作相关或与场景和动作的联合特征相关，并且可以量化，然而存在这一要求无法满足的实际情况。**同样对于一个动作集合，假设其奖励是不可知的，但同时选择多个动作，尤其是两个动作时，可以得到它们之间的比较结果并以此优化策略**，这一类问题需要完全不同的算法。
继续在推荐算法中，当一系列内容被推荐时，用户会点击之间的一部分，如果对于被点击的内容和未被点击的有提前设置好的奖励，系统可以得到反馈并更新模型参数，但这样花费成本设定的奖励是否合理需要长期的检验。如果不事先设定奖励，就只能得到推荐内容之间的比较，被点击的内容比未被点击的更好。
一个更合适的例子是商品的受欢迎程度比较。假设两个售货机分别出售百事和可口两种可乐，抽取它们多天的销售数据可以得到两种可乐的每日销量。如果采用绝对数量来衡量两个商标的受欢迎程度，很容易受到特殊情况影响，例如某一天可口的消费者非常渴而购买了大量饮料，使得可口的销售总量大幅上升。长期对比二者的相对销量则会更合理。
首先假设一定有一个最优的动作比其它动作都好，并且有一个衡量两个动作相对好坏的函数。

### 暴力搜索

随机初始化一个偏好矩阵，从好到坏排列了所有动作；
选择最好的动作和一个其它动作，比较，重复一定次数，选择一个对决其它动作都能高概率获胜的动作即为最好动作。

### 打败均值

初始化每个动作的胜利次数、比较次数、胜利与比较次数的商（以下称为优度）以及最好的动作；
随机选择比较次数最少的动作，与最好的动作相比，根据结果更新胜利次数和比较次数；
此时，如果新动作获胜，根据优度和一些超参数判别新动作是否更好，如果判断条件成立，用新动作代替原来的最优动作，更新一些参数后进入下一轮比较；
重复上两步，直到替代次数、比较次数或迭代次数达到上限。
实际上，此算法和上个算法仅仅是对传递性的假设不同。

### 野蛮选择

相比于以上两种算法，在选择和比较中，当一个动作输给另一个时，输的动作就不可能是最优的动作，因此不会继续选择它。
这个改进极大提升了性能。

### 友好辩论/自辩论

不再选择最好的动作和任意一个动作相比，而是任选两个动作，或者将最好的动作视为一个随时变化的动作。
假设有两个算法，分别选择了一个动作，则需要比较这两个动作并反馈给两个算法，重复。
这样可以假设动态变化的环境。
或者用一个算法每一次迭代选择两个动作，可以进一步降低训练成本。

ZhGan 2021.11.27
